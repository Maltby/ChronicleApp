Both Python scripts are ran manually, on a local machine. Plans include automating both scripts to stay up to date on new Gutenberg releases, by running scripts on EC2.

I found “metadataPull.py” on GitHub, and made some minor tweaks to handle null metadata as well as push all relevant data to AWS RDS. The script pulls the Gutenberg repo and gives access to all 58,000+ books and their metadata including title, author, book id, etc.

After saving all metadata, I needed a way to intake the books themselves, and parse them by chapter. “HtmlToChapter” uses Gutenberg url formatting to dynamically create links for each book, then pull down the HTML representation of such book. Once the HTML is received, the books are parsed based upon HTML headers and cut into chapters (work needs to be done to correctly intake all books, as the formatting is inconsistent from one book to the next). Once we have the chapters, we break them up into chunks of fifteen-hundred characters (the Polly character-per-query limit) and request speech synthesis from AWS Polly. We wait until all sections for a chapter have been synthesized, then concatenate all files into a single MP3 representing the chapter. The chapter is then uploaded to AWS S3. This process is done for each chapter, of each desired book, than the AWS RDS PostgreSQL “booksmain” database is updated with the books chapters and the audio file locations.